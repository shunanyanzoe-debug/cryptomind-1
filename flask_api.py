# # flask_api.py
# from flask import Flask, jsonify
# from flask_cors import CORS
# from pathlib import Path
# import pandas as pd
#
# # âœ… ä½ çš„ stage3 ç­–ç•¥ä¸»å‡½æ•°ï¼ˆå»ºè®®æ˜¯ run_stage3.py ä¸­çš„ main å‡½æ•°ï¼‰
# from run_stage3 import main
#
# app = Flask(__name__)
# CORS(app)  # å…è®¸å‰ç«¯è·¨åŸŸè°ƒç”¨è¿™ä¸ªAPI
#
# @app.route("/api/generate-weights", methods=["GET"])
# def generate_weights():
#     try:
#         # âœ… æ‰§è¡Œå›æµ‹ä¸é¢„æµ‹ï¼ˆä¼šè¾“å‡º CSV æ–‡ä»¶ï¼‰
#         main()
#
#         # âœ… è¯»å–æœ€æ–°ä¸€å‘¨çš„æ¨èæŠ•èµ„ç»„åˆï¼ˆæ¥è‡ª enet_sentiment ç­–ç•¥ï¼‰
#         pred_path = Path("stage3-4_result/data/pred_enet_sentiment.csv")
#         df = pd.read_csv(pred_path)
#         latest_date = df["date"].max()
#         latest = df[df["date"] == latest_date].sort_values("y_pred", ascending=False).head(10)
#
#         output = latest[["symbol", "y_pred"]].rename(columns={"y_pred": "predicted_return"})
#         return jsonify(output.to_dict(orient="records"))
#
#     except Exception as e:
#         return jsonify({"error": str(e)})
#
# if __name__ == "__main__":
#     app.run(debug=True, port=5000)





from flask import Flask, jsonify, request
from flask_cors import CORS
import pandas as pd
import numpy as np
from pathlib import Path
from stage3 import rolling_weekly_prediction
from run_stage3 import main


# å¯é€‰ï¼šç”¨äºæ¥å…¥ OpenAI Chat APIï¼ˆä»…å½“ä½ éœ€è¦ï¼‰
# import openai
# openai.api_key = "ä½ çš„ API Key"

app = Flask(__name__)
CORS(app)

# @app.route("/api/generate-weights", methods=["GET"])
# def generate_weights():
#     try:
#         # è¯»å–é¢„æµ‹ç»“æœ CSV æ–‡ä»¶
#         csv_path = Path("stage3-4_result/data/pred_enet_market.csv")
#         df = pd.read_csv(csv_path)
#
#         # ç¡®ä¿åŒ…å«å¿…è¦åˆ—
#         if not {"date", "symbol", "y_pred"}.issubset(df.columns):
#             return jsonify({"error": "Missing required columns in CSV"}), 400
#
#         # è½¬æ¢æ—¥æœŸåˆ—ä¸º datetime ç±»å‹
#         df["date"] = pd.to_datetime(df["date"])
#
#         # é€‰æ‹©æœ€æ–°æ—¥æœŸçš„æ•°æ®
#         latest_date = df["date"].max()
#         latest_df = df[df["date"] == latest_date].copy()
#
#         # è¿‡æ»¤æ‰é¢„æµ‹å€¼è¿‡å°çš„èµ„äº§ï¼ˆå¯é€‰ï¼‰
#         latest_df = latest_df[latest_df["y_pred"] > 0]
#
#         # é€‰å– top 10 é¢„æµ‹å€¼èµ„äº§
#         latest_df = latest_df.nlargest(20, "y_pred")
#
#         # å½’ä¸€åŒ–æƒé‡
#         total_pred = latest_df["y_pred"].sum()
#         latest_df["weight"] = latest_df["y_pred"] / total_pred
#
#         # æ„å»ºå‰ç«¯éœ€è¦çš„è¿”å›æ ¼å¼
#         result = [
#             {
#                 "symbol": row["symbol"],
#                 "predicted_return": round(row["weight"], 6)
#             }
#             for _, row in latest_df.iterrows()
#         ]
#
#         return jsonify(result)
#
#     except Exception as e:
#         return jsonify({"error": str(e)}), 500



# @app.route("/api/generate-weights", methods=["GET"])
# def generate_weights():
#     try:
#         # âœ… æ‰§è¡Œæ»šåŠ¨é¢„æµ‹ï¼ŒåŠ¨æ€æ›´æ–°æœ€æ–°ä¸€å‘¨çš„é¢„æµ‹
#         df = pd.read_csv("stage_2_merged_data.csv", parse_dates=["date"])
#         save_dir = Path("stage3-4_result/data")
#         save_dir.mkdir(parents=True, exist_ok=True)
#         rolling_weekly_prediction(df, save_dir, roll_window=52)
#
#         # âœ… ä»æœ€æ–°çš„é¢„æµ‹ç»“æœ CSV ä¸­é€‰å‡ºæœ€æ–°ä¸€å‘¨çš„ top 10 æƒé‡
#         pred_df = pd.read_csv(save_dir / "pred_enet_market.csv", parse_dates=["date"])
#         latest_date = pred_df["date"].max()
#         latest_week_df = pred_df[pred_df["date"] == latest_date].copy()
#
#         # âœ… æŒ‰é¢„æµ‹å€¼æ’åºï¼Œæå– top 10
#         top_df = latest_week_df.sort_values("y_pred", ascending=False).head(20)
#         top_df["predicted_return"] = top_df["y_pred"]
#         result = top_df[["symbol", "predicted_return"]].to_dict(orient="records")
#
#         return jsonify(result)
#
#     except Exception as e:
#         return jsonify({"error": str(e)}), 500


@app.route("/api/generate-weights", methods=["GET"])
def generate_weights():
    try:
        # è¿è¡Œé¢„æµ‹
        main()

        # è¯»å–ç»“æœ
        pred_path = Path("stage3-4_result/data/pred_enet_sentiment.csv")
        df = pd.read_csv(pred_path)
        latest_date = df["date"].max()
        latest = df[df["date"] == latest_date].sort_values("y_pred", ascending=False)

        # âœ… ä»å‰ç«¯ URL è·å– top_n å‚æ•°ï¼ˆé»˜è®¤ä¸º10ï¼‰
        top_n = int(request.args.get("top_n", 10))
        latest = latest.head(top_n)

        output = latest[["symbol", "y_pred"]].rename(columns={"y_pred": "predicted_return"})
        return jsonify(output.to_dict(orient="records"))

    except Exception as e:
        return jsonify({"error": str(e)})


@app.route("/api/ask", methods=["POST"])
def ask_ai():
    try:
        data = request.get_json()
        question = data.get("question", "")

        if not question:
            return jsonify({"answer": "âŒ No question received."})

        # â—å¦‚æœä½ æ¥å…¥ OpenAI APIï¼Œå–æ¶ˆæ³¨é‡Šä»¥ä¸‹å†…å®¹ğŸ‘‡
        # response = openai.ChatCompletion.create(
        #     model="gpt-4",
        #     messages=[
        #         {"role": "system", "content": "You are a helpful financial assistant."},
        #         {"role": "user", "content": question}
        #     ]
        # )
        # answer = response["choices"][0]["message"]["content"]

        # ä¸´æ—¶ mock æ¨¡å¼è¿”å›å›ºå®šç­”æ¡ˆ
        answer = "ğŸ’¡ This is a simulated answer. Please connect to a real AI service."

        return jsonify({"answer": answer})

    except Exception as e:
        return jsonify({"answer": f"âŒ Failed to fetch AI answer: {str(e)}"})


if __name__ == "__main__":
    app.run(debug=True)





